{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-05T20:45:15.356014400Z",
     "start_time": "2023-07-05T20:45:14.648586800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\py37\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: \n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "python的用法 --》 tensor数据类型\n",
    "通过transforms.Totensor看两个问题\n",
    "- transfroms该如何使用（python）\n",
    "- 为什么要使用tensor数据类型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=768x512 at 0x19FF3ABB188>\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "# Totensor将PIL Image或者numpy.array数据转换为tensor\n",
    "img_path = r\"D:\\PycharmProjects\\xiaotudui_pytorch_tutorial\\dataset\\train\\ants_image\\0013035.jpg\"\n",
    "img = Image.open(img_path)\n",
    "print(img)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T20:54:54.808462800Z",
     "start_time": "2023-07-05T20:54:54.799107900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# transfroms该如何使用（python）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3137, 0.3137, 0.3137,  ..., 0.3176, 0.3098, 0.2980],\n",
      "         [0.3176, 0.3176, 0.3176,  ..., 0.3176, 0.3098, 0.2980],\n",
      "         [0.3216, 0.3216, 0.3216,  ..., 0.3137, 0.3098, 0.3020],\n",
      "         ...,\n",
      "         [0.3412, 0.3412, 0.3373,  ..., 0.1725, 0.3725, 0.3529],\n",
      "         [0.3412, 0.3412, 0.3373,  ..., 0.3294, 0.3529, 0.3294],\n",
      "         [0.3412, 0.3412, 0.3373,  ..., 0.3098, 0.3059, 0.3294]],\n",
      "\n",
      "        [[0.5922, 0.5922, 0.5922,  ..., 0.5961, 0.5882, 0.5765],\n",
      "         [0.5961, 0.5961, 0.5961,  ..., 0.5961, 0.5882, 0.5765],\n",
      "         [0.6000, 0.6000, 0.6000,  ..., 0.5922, 0.5882, 0.5804],\n",
      "         ...,\n",
      "         [0.6275, 0.6275, 0.6235,  ..., 0.3608, 0.6196, 0.6157],\n",
      "         [0.6275, 0.6275, 0.6235,  ..., 0.5765, 0.6275, 0.5961],\n",
      "         [0.6275, 0.6275, 0.6235,  ..., 0.6275, 0.6235, 0.6314]],\n",
      "\n",
      "        [[0.9137, 0.9137, 0.9137,  ..., 0.9176, 0.9098, 0.8980],\n",
      "         [0.9176, 0.9176, 0.9176,  ..., 0.9176, 0.9098, 0.8980],\n",
      "         [0.9216, 0.9216, 0.9216,  ..., 0.9137, 0.9098, 0.9020],\n",
      "         ...,\n",
      "         [0.9294, 0.9294, 0.9255,  ..., 0.5529, 0.9216, 0.8941],\n",
      "         [0.9294, 0.9294, 0.9255,  ..., 0.8863, 1.0000, 0.9137],\n",
      "         [0.9294, 0.9294, 0.9255,  ..., 0.9490, 0.9804, 0.9137]]])\n"
     ]
    }
   ],
   "source": [
    "tensor_trans = transforms.ToTensor()\n",
    "# 创建一个Totensor实例化类\n",
    "tensor_img = tensor_trans(img)\n",
    "print(tensor_img)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T20:57:35.543793Z",
     "start_time": "2023-07-05T20:57:35.486058900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 为什么要使用tensor数据类型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# tensor数据类型包含反向传播，梯度等理论参数属性"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# np.arrary转tensor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv_img = cv2.imread(img_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T21:06:25.937269300Z",
     "start_time": "2023-07-05T21:06:25.912228600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T21:08:11.372049300Z",
     "start_time": "2023-07-05T21:08:11.171149600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"logs\")\n",
    "writer.add_image(\"Tensor_img\", tensor_img)\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T21:10:45.065703Z",
     "start_time": "2023-07-05T21:10:44.941400300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 归一化Normalize"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3725, -0.3725, -0.3725,  ..., -0.3647, -0.3804, -0.4039],\n",
      "         [-0.3647, -0.3647, -0.3647,  ..., -0.3647, -0.3804, -0.4039],\n",
      "         [-0.3569, -0.3569, -0.3569,  ..., -0.3725, -0.3804, -0.3961],\n",
      "         ...,\n",
      "         [-0.3176, -0.3176, -0.3255,  ..., -0.6549, -0.2549, -0.2941],\n",
      "         [-0.3176, -0.3176, -0.3255,  ..., -0.3412, -0.2941, -0.3412],\n",
      "         [-0.3176, -0.3176, -0.3255,  ..., -0.3804, -0.3882, -0.3412]],\n",
      "\n",
      "        [[ 0.1843,  0.1843,  0.1843,  ...,  0.1922,  0.1765,  0.1529],\n",
      "         [ 0.1922,  0.1922,  0.1922,  ...,  0.1922,  0.1765,  0.1529],\n",
      "         [ 0.2000,  0.2000,  0.2000,  ...,  0.1843,  0.1765,  0.1608],\n",
      "         ...,\n",
      "         [ 0.2549,  0.2549,  0.2471,  ..., -0.2784,  0.2392,  0.2314],\n",
      "         [ 0.2549,  0.2549,  0.2471,  ...,  0.1529,  0.2549,  0.1922],\n",
      "         [ 0.2549,  0.2549,  0.2471,  ...,  0.2549,  0.2471,  0.2627]],\n",
      "\n",
      "        [[ 0.8275,  0.8275,  0.8275,  ...,  0.8353,  0.8196,  0.7961],\n",
      "         [ 0.8353,  0.8353,  0.8353,  ...,  0.8353,  0.8196,  0.7961],\n",
      "         [ 0.8431,  0.8431,  0.8431,  ...,  0.8275,  0.8196,  0.8039],\n",
      "         ...,\n",
      "         [ 0.8588,  0.8588,  0.8510,  ...,  0.1059,  0.8431,  0.7882],\n",
      "         [ 0.8588,  0.8588,  0.8510,  ...,  0.7725,  1.0000,  0.8275],\n",
      "         [ 0.8588,  0.8588,  0.8510,  ...,  0.8980,  0.9608,  0.8275]]])\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "# input-mean/std\n",
    "trans_norm = transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
    "img_norm = trans_norm(tensor_img)\n",
    "print(img_norm)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T21:30:10.307003200Z",
     "start_time": "2023-07-05T21:30:10.296976Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3137)\n",
      "tensor(-0.3725)\n"
     ]
    }
   ],
   "source": [
    "print(tensor_img[0][0][0])\n",
    "print(img_norm[0][0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T21:33:02.300669200Z",
     "start_time": "2023-07-05T21:33:02.289223800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Resize使用"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 512)\n",
      "tensor([[[0.3137, 0.3137, 0.3176,  ..., 0.3137, 0.3137, 0.3020],\n",
      "         [0.3176, 0.3176, 0.3176,  ..., 0.3098, 0.3137, 0.3020],\n",
      "         [0.3216, 0.3216, 0.3176,  ..., 0.3059, 0.3137, 0.3059],\n",
      "         ...,\n",
      "         [0.3412, 0.3373, 0.3373,  ..., 0.0196, 0.2196, 0.3608],\n",
      "         [0.3412, 0.3373, 0.3373,  ..., 0.3490, 0.3373, 0.3373],\n",
      "         [0.3412, 0.3373, 0.3373,  ..., 0.3529, 0.3137, 0.3216]],\n",
      "\n",
      "        [[0.5922, 0.5922, 0.5961,  ..., 0.5922, 0.5922, 0.5804],\n",
      "         [0.5961, 0.5961, 0.5961,  ..., 0.5882, 0.5922, 0.5804],\n",
      "         [0.6000, 0.6000, 0.5961,  ..., 0.5843, 0.5922, 0.5843],\n",
      "         ...,\n",
      "         [0.6275, 0.6235, 0.6235,  ..., 0.1020, 0.4157, 0.6157],\n",
      "         [0.6275, 0.6235, 0.6235,  ..., 0.5373, 0.5882, 0.6078],\n",
      "         [0.6275, 0.6235, 0.6235,  ..., 0.6392, 0.6275, 0.6275]],\n",
      "\n",
      "        [[0.9137, 0.9137, 0.9176,  ..., 0.9137, 0.9137, 0.9020],\n",
      "         [0.9176, 0.9176, 0.9176,  ..., 0.9098, 0.9137, 0.9020],\n",
      "         [0.9216, 0.9216, 0.9176,  ..., 0.9059, 0.9137, 0.9059],\n",
      "         ...,\n",
      "         [0.9294, 0.9255, 0.9255,  ..., 0.1961, 0.6353, 0.9059],\n",
      "         [0.9294, 0.9255, 0.9255,  ..., 0.7922, 0.9098, 0.9451],\n",
      "         [0.9294, 0.9255, 0.9255,  ..., 0.9412, 0.9569, 0.9373]]])\n"
     ]
    }
   ],
   "source": [
    "print(img.size)\n",
    "trans_resize = transforms.Resize((512,512))\n",
    "img_resize = trans_resize(img)\n",
    "img_resize = tensor_trans(img_resize)\n",
    "print(img_resize)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T21:40:07.408767600Z",
     "start_time": "2023-07-05T21:40:07.390220700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "writer = SummaryWriter(r\"D:\\PycharmProjects\\xiaotudui_pytorch_tutorial\\logs\")\n",
    "writer.add_image(\"Resize\",img_resize,0)\n",
    "writer.add_image(\"Resize\",tensor_img,1)\n",
    "writer.close()\n",
    "# tensorboard确实好用"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T21:43:52.930805Z",
     "start_time": "2023-07-05T21:43:52.719003800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Compose - resize -2\n",
    "trans_resize_2 = transforms.Resize(512)\n",
    "# compose()参数需要是一个列表\n",
    "# PIL -> PIL -> tensor\n",
    "trans_compose = transforms.Compose([trans_resize_2,tensor_trans])\n",
    "img_resize_2 = trans_compose(img)\n",
    "writer = SummaryWriter(r\"D:\\PycharmProjects\\xiaotudui_pytorch_tutorial\\logs\")\n",
    "writer.add_image(\"Resize\",img_resize_2,2)\n",
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T21:49:30.767363700Z",
     "start_time": "2023-07-05T21:49:30.623152900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-py37-py",
   "language": "python",
   "display_name": "Python [conda env:py37] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
